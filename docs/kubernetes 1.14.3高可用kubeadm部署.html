<html>
<head>
  <title>Evernote Export</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/600718 (zh-CN, DDL); Windows/6.3.0 (Win64);"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="11456"/>

<div>
<span><div><div># 拓补图</div><div><img src="kubernetes 1.14.3高可用kubeadm部署_files/Image.png" type="image/png" data-filename="Image.png"/></div><div><br/></div><div>如上图，本次高可用部署使用堆叠etcd模式进行部署。每一个master节点（control plane node）运行kube-apiserver、kube-scheduler、kube-controller-manager，每一个 master节点同时也运行etcd作为集群运行状态存储。其中kube-apiserver通过keepalived+haproxy以负载均衡方式为node节点提供服务，其中kube-proxy转发模式采用ipvs</div><div><br/></div><div># 部署流程</div><div>1. 环境初始化，部署梯子</div><div>2. 配置keepalived+haproxy，此处只做了一边节点</div><div>3. 部署所有master，node的k8s与docker环境，视情况导入镜像</div><div>4. 配置第一个k8s的master，将其他master加入集群</div><div>5. 配置node，将node加入集群</div><div>6. 配置网络插件</div><div><br/></div><div># 版本</div><div>## 系统版本</div><div>CentOS Linux release 7.5.1804 (Core)</div><div><br/></div><div>## k8s集群版本</div><div>kubeadm-1.14.3-0</div><div>kubectl-1.14.3-0</div><div>kubelet-1.14.3-0 </div><div>kubernetes-cni-0.7.5-0</div><div>docker-ce-18.09.2-3.el7</div><div><br/></div><div>## 梯子</div><div>shadowsocks-2.8.2.tar.gz</div><div>privoxy-3.0.26</div><div><br/></div><hr/><div># 环境初始化</div><div>## 设置ip地址</div><div>（略）</div><div><br/></div><div>## 所有机器配置/etc/hosts</div><div>vim /etc/hosts</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>192.168.70.3 ss ss.jckvm.top</div><div>192.168.70.4 lb lb.jckvm.top</div><div>192.168.70.30 master01 master01.jckvm.top</div><div>192.168.70.31 master02 master02.jckvm.top</div><div>192.168.70.32 master03 master03.jckvm.top</div><div>192.168.70.33 node01 node01.jckvm.top</div><div>192.168.70.34 node02 node02.jckvm.top</div><div>192.168.70.35 node03 node03.jckvm.top</div><div>192.168.70.5 vip vip.jckvm.top<span>    </span><span>    </span><span>    # haproxy不要这条</span></div></div><div><br/></div><div>## 设置主机名</div><div>systemctl restart network</div><div>exec bash</div><div><br/></div><div>## 配置yum源</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>yum -y install epel-release</div><div>yum clean all</div><div>yum -y groupinstall 'Compatibility libraries' &quot;Base&quot; &quot;Development tools&quot;</div><div>yum -y groupinstall &quot;debugging Tools&quot; &quot;Dial-up Networking Support&quot;</div><div>yum -y install lrzsz  bash-completion</div><div>yum -y install iptables-services</div><div>yum -y install python-pip</div></div><div><br/></div><div>## 关闭selinux</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>setenforce 0 </div><div>sed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config</div></div><div><br/></div><div>## 时区配置与时间同步配置</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>\cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime </div><div>ntpdate <a href="http://ntp1.aliyun.com/">ntp1.aliyun.com</a> </div><div>echo &quot;*/5 * * * * /usr/sbin/ntpdate <a href="http://ntp1.aliyun.com/">ntp1.aliyun.com</a>&quot; &gt;&gt; /var/spool/cron/root</div></div><div><br/></div><div>## 防火墙配置</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>setenforce 0</div><div>systemctl stop firewalld</div><div>systemctl disable firewalld</div><div>setenforce 0</div><div>iptables -F</div><div>iptables -F -t nat</div><div>iptables -X </div><div>iptables -Z</div><div>service iptables save</div><div>systemctl restart iptables</div><div>systemctl enable iptables</div></div><div><br/></div><hr/><div># 部署梯子</div><div>下面操作在192.168.70.3 ss ss.jckvm.top</div><div>由于不可描述原因，我们身处世界上最大的局域网之中，需要配置个代理服务帮我们完成软件包下载工作</div><div>部署使用到两个软件包：</div><div>shadowsocks-2.8.2.tar.gz</div><div>privoxy-3.0.26</div><div><br/></div><div>链接：<a href="https://pan.baidu.com/s/1WItdWg6_bMsbkJ_q9zcIPA">https://pan.baidu.com/s/1WItdWg6_bMsbkJ_q9zcIPA</a></div><div>提取码：edlo</div><div><br/></div><div>## 体面提供两种办法进行安装shadowsocks小飞机</div><div>第一种在线安装:</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>pip install shadowsocks</div></div><div><br/></div><div>第二种离线安装:</div><div>若第一种办法因不可描述原因安装失败可用离线安装办法</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div># 创建安装包存放目录</div><div>mkdir /home/sha-client</div><div><br/></div><div># 下载安装包，上传到/home/sha-client</div><div>链接：<a href="https://pan.baidu.com/s/1WItdWg6_bMsbkJ_q9zcIPA">https://pan.baidu.com/s/1WItdWg6_bMsbkJ_q9zcIPA</a></div><div>提取码：edlo</div><div><br/></div><div># 安装sha客户端</div><div>pip install --no-index --find-links=/home/sha-client shadowsocks</div></div><div><br/></div><div>## 配置shadowsocks连接文件</div><div>帐号密码这个需要自己花点心思,你们懂的</div><div>mkdir /etc/shadowsocks</div><div>vim /etc/shadowsocks/shadowsocks.json</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>{</div><div>    &quot;server&quot;:&quot;23.133.64.3&quot;,     # 梯子服务器密码</div><div>    &quot;server_port&quot;:24793,         # 梯子服务器端口</div><div>    &quot;local_address&quot;: &quot;127.0.0.1&quot;,  # 本地ip地址</div><div>    &quot;local_port&quot;:1080,             # 本地端口</div><div>    &quot;password&quot;:&quot;MLWJYQi&quot;,         # 连接密码</div><div>    &quot;timeout&quot;:300,                # 等待超时时间</div><div>    &quot;method&quot;:&quot;rc4-md5&quot;,            # 加密方式</div><div>    &quot;fast_open&quot;: false,         # 是否降低延迟</div><div>    &quot;workers&quot;: 1                 # 进程数</div><div>}</div></div><div><br/></div><div>## 配置启动文件</div><div>vim /etc/systemd/system/shadowsocks.service</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>[Unit]</div><div>Description=Shadowsocks</div><div>[Service]</div><div>TimeoutStartSec=0</div><div>ExecStart=/usr/bin/sslocal -c /etc/shadowsocks/shadowsocks.json</div><div>[Install]</div><div>WantedBy=multi-user.target</div></div><div><br/></div><div>## 启动服务</div><div>systemctl enable shadowsocks.service</div><div>systemctl restart shadowsocks.service</div><div>systemctl status shadowsocks.service</div><div><br/></div><div>## 验证是否可用</div><div>curl --socks5 127.0.0.1:1080 <a href="http://httpbin.org/ip">http://httpbin.org/ip</a></div><div>下面为返回正常结果</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>{</div><div>  &quot;origin&quot;: &quot;服务器地址&quot;</div><div>}</div></div><div><br/></div><div>## 安装privoxy，用来代理k8s下载请求</div><div>yum install privoxy -y</div><div><br/></div><div>## 修改配置文件</div><div>vim /etc/privoxy/config</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div># 如果只为本机代理此处不用改，8118端口就是接受代理docker代理请求的端口</div><div># 如果为其他主机进行代理的话需要修改成listen-address  0.0.0.0:8118</div><div>listen-address  127.0.0.1:8118</div><div>forward-socks5t / 127.0.0.1:1080 .</div></div><div><br/></div><div>## 启动</div><div>systemctl enable privoxy</div><div>systemctl start privoxy</div><div>systemctl status privoxy</div><div><br/></div><div>## 测试是否可以请求</div><div>curl 192.168.16.36:8118</div><div>正常返回</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>Invalid header received from client.</div></div><div><br/></div><div># 验证是否成功部署好代理</div><div>## 在/etc/profile添加如下内容</div><div>vim /etc/profile</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>PROXY_HOST=127.0.0.1</div><div>export all_proxy=http://$PROXY_HOST:8118</div><div>export ftp_proxy=http://$PROXY_HOST:8118</div><div>export https_proxy=http://$PROXY_HOST:8118</div><div>export http_proxy=http://$PROXY_HOST:8118</div></div><div><br/></div><div># 刷新变量</div><div>export no_proxy=localhost,172.16.0.0/16,192.168.0.0/24,127.0.0.1,10.10.0.0/16</div><div>source /etc/profile</div><div><br/></div><div># 测试</div><div>curl -I <a href="http://www.google.com/">www.google.com</a></div><div><br/></div><div># 取消代理方法</div><div>while read var; do unset $var; done &lt; &lt;(env | grep -i proxy | awk -F= '{print $1}')</div><div>去掉/etc/profile添加的内容</div><div>刷新变量</div><div>source /etc/profile</div><div><br/></div><hr/><div><br/></div><div># 配置keepalived+haproxy</div><div>下面只部署测试，所以只部署单个节点，但是在后面还是给出配置文件</div><div>生产环境中对应部署双节点即可</div><div>注意：</div><div><span>    </span>之所有没有沿用网上其他文档中采用master节点来部署负载均衡是考虑到api-server监听的是6443端口。因此当延用master节点的话做负载均衡中vip时，需要修改转发vip的监听端口因为不能同时监听6443。修改了此端口的话也许在后期部署其他组件时（例如监控），需要修改相应的api-server监听端口，为免除此麻烦，因此不在master上进行部署。</div><div><br/></div><div>## 配置内核参数</div><div>[root@lb ~]# vim /etc/sysctl.d/haproxyd.conf</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>net.ipv4.ip_nonlocal_bind = 1</div><div>net.ipv4.ip_forward = 1</div></div><div>[root@lb ~]# sysctl -p /etc/sysctl.d/haproxyd.conf</div><div><img src="kubernetes 1.14.3高可用kubeadm部署_files/Image [1].png" type="image/png" data-filename="Image.png"/></div><div><img src="kubernetes 1.14.3高可用kubeadm部署_files/Image [2].png" type="image/png" data-filename="Image.png"/></div><div><br/></div><div>## 安装keepalived+haproxy</div><div>[root@lb ~]# yum install -y keepalived haproxy</div><div><br/></div><div>## 配置keepalived</div><div>[root@lb ~]# cd /etc/keepalived/</div><div>[root@lb keepalived]# cp keepalived.conf keepalived.conf.bak</div><div>[root@lb keepalived]# vim keepalived.conf</div><div>主配置文件</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>! Configuratile for keepalived</div><div>global_defs {</div><div>notification_email {</div><div>76439984@qq.com</div><div>      }</div><div>notification_email_from keepalived@ptmind.com</div><div>smtp_server 127.0.0.1</div><div>smtp_connect_timeout 30</div><div>router_id lb1</div><div>}</div><div><br/></div><div>vrrp_script check_apiserver {</div><div>     script &quot;killall -0 haproxy&quot;</div><div>     interval 5</div><div>     weight -20</div><div>     fall 3</div><div>     rise 1</div><div>     }</div><div><br/></div><div>vrrp_instance VIP_250 {</div><div>    state MASTER</div><div>    interface eth0</div><div>    virtual_router_id 250</div><div>    priority 100</div><div>    advert_int 1</div><div>    authentication {</div><div>        auth_type PASS</div><div>        auth_pass 890iop</div><div>    }</div><div>    </div><div>    track_script {</div><div>      check_apiserver</div><div>     }</div><div>    </div><div>    virtual_ipaddress {</div><div>        192.168.70.5/24</div><div>    }</div><div>}</div></div><div><br/></div><div>此处不部署从接节点，但给出配置文件</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>! Configuratile for keepalived</div><div>global_defs {</div><div>notification_email {</div><div>76439984@qq.com</div><div>      }</div><div>notification_email_from keepalived@ptmind.com</div><div>smtp_server 127.0.0.1</div><div>smtp_connect_timeout 30</div><div>router_id lb1</div><div>}</div><div><br/></div><div>vrrp_script check_apiserver {</div><div>     script &quot;killall -0 haproxy&quot;</div><div>     interval 5</div><div>     weight -20</div><div>     fall 3</div><div>     rise 1</div><div>     }</div><div><br/></div><div>vrrp_instance VIP_250 {</div><div>    state BACKUP</div><div>    interface eth0</div><div>    virtual_router_id 250</div><div>    priority 99</div><div>    advert_int 1</div><div>    authentication {</div><div>        auth_type PASS</div><div>        auth_pass 890iop</div><div>    }</div><div>    </div><div>    track_script {</div><div>      check_apiserver</div><div>     }</div><div>    </div><div>    virtual_ipaddress {</div><div>        192.168.70.5/24</div><div>    }</div><div>}</div></div><div><br/></div><div>## 配置haproxy</div><div>[root@lb keepalived]# cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak</div><div>[root@lb keepalived]# vim /etc/haproxy/haproxy.cfg</div><div>主从配置文件相同</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>global</div><div>    log         127.0.0.1 local2</div><div>    chroot      /var/lib/haproxy</div><div>    pidfile     /var/run/haproxy.pid</div><div>    maxconn     4000</div><div>    user        haproxy</div><div>    group       haproxy</div><div>    daemon</div><div>    stats socket /var/lib/haproxy/stats</div><div><br/></div><div>defaults</div><div>    mode                    tcp</div><div>    log                     global</div><div>    option                  httplog</div><div>    option                  dontlognull</div><div>    option http-server-close</div><div>    option forwardfor       except 127.0.0.0/8</div><div>    option                  redispatch</div><div>    retries                 3</div><div>    timeout http-request    10s</div><div>    timeout queue           1m</div><div>    timeout connect         10s</div><div>    timeout client          1m</div><div>    timeout server          1m</div><div>    timeout http-keep-alive 10s</div><div>    timeout check           10s</div><div>    maxconn                 3000</div><div><br/></div><div># 状态页面配置段</div><div>listen status</div><div>    mode http</div><div>    bind *:8000</div><div>    stats enable</div><div>    stats hide-version</div><div>    stats uri /stats_k8s</div><div>    stats auth k8sadm:k8sadm</div><div>    stats admin if TRUE</div><div>    stats realm Haproxy\ Statistics</div><div><br/></div><div># apiserver负载均衡配置段    </div><div>frontend kubernetes</div><div>    bind *:6443</div><div>    mode tcp</div><div>    default_backend kubernetes-master</div><div><br/></div><div>backend kubernetes-master</div><div>    balance roundrobin</div><div>    server master01 192.168.70.30:6443 check port 6443 inter 5000 fall 5</div><div>    server master02 192.168.70.31:6443 check port 6443 inter 5000 fall 5</div><div>    server master03 192.168.70.32:6443 check port 6443 inter 5000 fall 5</div></div><div><br/></div><div>## 启动keepalived+haproxy</div><div>[root@lb keepalived]# systemctl enable keepalived.service</div><div>[root@lb keepalived]# systemctl restart keepalived.service</div><div>[root@lb keepalived]# systemctl enable haproxy.service</div><div>[root@lb keepalived]# systemctl restart haproxy.service</div><div><br/></div><div>## 测试，浏览器访问 <a href="http://192.168.70.5:8000/stats_k8s">http://192.168.70.5:8000/stats_k8s</a></div><div>帐号k8sadm</div><div>密码k8sadm</div><div><img src="kubernetes 1.14.3高可用kubeadm部署_files/Image [3].png" type="image/png" data-filename="Image.png"/></div><div><br/></div><hr/><div><br/></div><div># 部署所有master，node的docker环境</div><div>## 配置docker的yum源</div><div>cd /etc/yum.repos.d</div><div>wget <a href="https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo">https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</a></div><div><br/></div><div>## 安装配置docker</div><div>yum list docker-ce --showduplicates | sort -r</div><div>yum install docker-ce-18.09.2-3.el7</div><div><br/></div><div>## 将docker源修改为阿里云镜像加速器</div><div>mkdir /etc/docker/</div><div>vim /etc/docker/daemon.json</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>{</div><div>&quot;registry-mirrors&quot;: [&quot;<a href="https://88a45eyb.mirror.aliyuncs.com/">https://88a45eyb.mirror.aliyuncs.com&quot;,&quot;https://registry.docker-cn.com</a>&quot;],</div><div>&quot;dns&quot;: [&quot;223.5.5.5&quot;,&quot;223.6.6.6&quot;],</div><div>&quot;data-root&quot;: &quot;/data/docker&quot;</div><div>}</div></div><div><br/></div><div>## 打开ipvs转发功能</div><div>vim /etc/sysconfig/modules/ipvs.modules</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>#!/bin/bash</div><div>ipvs_mods_dir=&quot;/usr/lib/modules/$(uname -r)/kernel/net/netfilter/ipvs&quot;</div><div><br/></div><div>for i in $(ls $ipvs_mods_dir | grep -o &quot;^[^.]*&quot;); do</div><div>    /sbin/modinfo -F filename $i &amp;&gt; /dev/null</div><div>    if [ $? -eq 0 ]; then</div><div>        /sbin/modprobe $i</div><div>    fi    </div><div>done</div></div><div>chmod +x /etc/sysconfig/modules/ipvs.modules</div><div>sh /etc/sysconfig/modules/ipvs.modules</div><div><br/></div><div>##  配置docker使用代理</div><div>vim /usr/lib/systemd/system/docker.service</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div># 在ExecStart=/usr/bin/dockerd下面添加如下行</div><div>ExecStartPost=/usr/sbin/iptables -P FORWARD ACCEPT</div><div><br/></div><div># 在ExecReload=/bin/kill -s HUP $MAINPID添加如下行</div><div>Environment=&quot;HTTPS_PROXY=<a href="http://t6.wft.com:8118/">http://ss.jckvm.top:8118</a>&quot;</div><div>Environment=&quot;NO_PROXY=127.0.0.0/8,192.168.0.0/24,192.168.16.0/24&quot;</div></div><div><br/></div><div>systemctl enable docker</div><div>systemctl daemon-reload</div><div>systemctl restart docker</div><div><br/></div><div>## 测试是否可以通过代理下载镜像</div><div>docker pull k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1</div><div><br/></div><div>## 查看内核参数是否已经被修改如下</div><div>cat /proc/sys/net/bridge/bridge-nf-call-iptables</div><div>1   结果必须为1</div><div>cat /proc/sys/net/bridge/bridge-nf-call-ip6tables</div><div>1    结果必须为1</div><div><br/></div><div># 部署所有master，node的k8s环境</div><div>## 配置k8s的yum源</div><div>vim kubernetes.repo</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>[kubernetes]</div><div>name=k8s</div><div>baseurl=<a href="https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/">https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</a></div><div>gpgcheck=0</div><div>enable=1</div></div><div>yum repolist</div><div><br/></div><div>## master上安装k8s组件</div><div>注意：</div><div><span>    由于k8s版本更新快，所以使用yum安装的时候，当不指定版本时，安装的是最近的版本。指定版本时，安装的则是指定版本。</span><br/></div><div>如果需要安装旧版本，则需要注意其他组件的依赖关系。</div><div>安装思路：</div><div><span>    </span>安装指定版本(开始yum安装的时候先不要安装kubernetes-cni-0.6.0-0 看他需要哪一个版本的cni,yum的时候看报错提示,按照提示加上去再安装。kubeadm的版本跟k8s有直接关系,例如1.13只能安装k8s的1.13)<br/></div><div>### 指定旧版本安装：</div><div><span>    </span>yum  install kubectl-1.13.3-0 kubelet-1.13.3-0 kubeadm-1.13.3-0 kubernetes-cni-0.6.0-0<br/></div><div><br/></div><div>### 安装最近版本方法</div><div>yum install kubelet kubeadm kubectl</div><div><br/></div><div>### 本次使用1.14.3版本</div><div>yum list kubeadm kubectl kubelete --showduplicates | sort -r</div><div>yum  install kubectl-1.14.3-0 kubelet-1.14.3-0 kubeadm-1.14.3-0 kubernetes-cni-0.7.5-0</div><div><br/></div><div>## node上安装k8s组件</div><div>yum  install kubelet-1.14.3-0 kubeadm-1.14.3-0</div><div><br/></div><div>## 配置master，node的kebelet配置文件</div><div>vim /etc/sysconfig/kubelet</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>KUBELET_EXTRA_ARGS=&quot;--fail-swap-on=false&quot;</div></div><div><br/></div><div><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">kubelet</span>初次不要直接启动,只设置开机启动就OK</div><div>systemctl enable kubelet.service</div><div><br/></div><hr/><div># 配置master01节点，即第一个节点</div><div>### 镜像导入（当无法使用梯子时使用）</div><div>链接：<a href="https://pan.baidu.com/s/1W_fF8gwUOAJUrKxA1q4eiA">https://pan.baidu.com/s/1W_fF8gwUOAJUrKxA1q4eiA</a></div><div>提取码：zvny</div><div>docker image load -i <span style="min-height: 1pt; font-family: 微软雅黑; color: rgb(51, 51, 51);">k8s-master.gz</span></div><div><span style="min-height: 1pt; font-family: 微软雅黑; color: rgb(51, 51, 51);"><br/></span></div><div>### 生成master01上初始化的init配置文件</div><div>[root@master01 ~]# vim kubeadm-config.yaml</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>apiVersion: kubeadm.k8s.io/v1beta1</div><div>kind: ClusterConfiguration</div><div>kubernetesVersion: v1.14.3<span>    </span><span>    # k8s版本</span></div><div>apiServer:</div><div>  certSANs:<span>    </span><span>    </span><span>    </span><span>    </span><span>    </span><span>    # 证书别名</span></div><div>  - master01.jckvm.top<span>    </span><span>    </span><span>    </span><span>    # master01主机名</span></div><div>  - master02.jckvm.top<span>    </span><span>    </span><span>    </span><span>    </span># master02主机名</div><div>  - master03.jckvm.top<span>    </span><span>    </span><span>    </span><span>    </span># master03主机名</div><div>  - vip.jckvm.top<span>    </span><span>    </span><span>    </span><span>    </span><span>    </span><span> # vip域名</span></div><div>  - 192.168.70.30<span>    </span><span>    </span><span>    </span><span>    </span><span>     </span># master01的ip地址</div><div>  - 192.168.70.31<span>    </span><span>    </span><span>    </span><span>    </span><span>     </span># master02的ip地址</div><div>  - 192.168.70.32<span>    </span><span>    </span><span>    </span><span>    </span><span>     </span># master03的ip地址</div><div>  - 192.168.70.5<span>    </span><span>    </span><span>    </span><span>    </span><span>    </span><span>  </span># vip的ip地址</div><div>controlPlaneEndpoint: &quot;192.168.70.5:6443&quot;<span>    </span><span>    # apiserver调用的地址，应该可以写域名，未亲测</span></div><div>networking:</div><div>  podSubnet: &quot;10.244.0.0/16&quot;<span>    </span><span>    </span><span>    </span><span>         # pod分配网段 </span></div><div>---</div><div>apiVersion: kubeproxy.config.k8s.io/v1alpha1<span>    </span><span> # 如果需要将转发方式写成ipvs则配置此段，默认为iptables</span></div><div>kind: KubeProxyConfiguration</div><div>mode: &quot;ipvs&quot;</div></div><div><br/></div><div>### 列出需要下载的镜像</div><div>[root@master01 ~]# kubeadm config images list --config kubeadm-config.yaml</div><div><img src="kubernetes 1.14.3高可用kubeadm部署_files/Image [4].png" type="image/png" data-filename="Image.png"/></div><div><br/></div><div>### 下载镜像</div><div>[root@master01 ~]# kubeadm config images pull --config kubeadm-config.yaml</div><div><br/></div><div>### 测试初始化</div><div>[root@master01 ~]# kubeadm init --config kubeadm-config.yaml --experimental-upload-certs --dry-run  --ignore-preflight-errors=Swap</div><div><br/></div><div>### 初始化第一个master</div><div>[root@master01 ~]# kubeadm init --config kubeadm-config.yaml --experimental-upload-certs  --ignore-preflight-errors=Swap</div><div>初始化会出现以下信息</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>[root@master01 ~]# kubeadm init --config kubeadm-config.yaml --experimental-upload-certs --ignore-preflight-errors=Swap</div><div>[init] Using Kubernetes version: v1.14.3</div><div>[preflight] Running pre-flight checks</div><div>        [WARNING IsDockerSystemdCheck]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. Please follow the guide at https://kubernetes.io/docs/setup/cri/</div><div>        [WARNING Swap]: running with swap on is not supported. Please disable swap</div><div>[preflight] Pulling images required for setting up a Kubernetes cluster</div><div>[preflight] This might take a minute or two, depending on the speed of your internet connection</div><div>[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'</div><div>[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</div><div>[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</div><div>[kubelet-start] Activating the kubelet service</div><div>[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</div><div>[certs] Generating &quot;front-proxy-ca&quot; certificate and key</div><div>[certs] Generating &quot;front-proxy-client&quot; certificate and key</div><div>[certs] Generating &quot;etcd/ca&quot; certificate and key</div><div>[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</div><div>[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</div><div>[certs] Generating &quot;etcd/server&quot; certificate and key</div><div>[certs] etcd/server serving cert is signed for DNS names [master01 localhost] and IPs [192.168.70.30 127.0.0.1 ::1]</div><div>[certs] Generating &quot;etcd/peer&quot; certificate and key</div><div>[certs] etcd/peer serving cert is signed for DNS names [master01 localhost] and IPs [192.168.70.30 127.0.0.1 ::1]</div><div>[certs] Generating &quot;ca&quot; certificate and key</div><div>[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</div><div>[certs] Generating &quot;apiserver&quot; certificate and key</div><div>[certs] apiserver serving cert is signed for DNS names [master01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local master01.jckvm.top master02.jckvm.top master03.jckvm.top vip.jckvm.top] and IPs [10.96.0.1 192.168.70.30 192.168.70.5 192.168.70.30 192.168.70.31 192.168.70.32 192.168.70.5]</div><div>[certs] Generating &quot;sa&quot; key and public key</div><div>[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</div><div>[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</div><div>[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</div><div>[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</div><div>[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</div><div>[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</div><div>[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</div><div>[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</div><div>[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</div><div>[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</div><div>[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</div><div>[apiclient] All control plane components are healthy after 20.003436 seconds</div><div>[upload-config] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</div><div>[kubelet] Creating a ConfigMap &quot;kubelet-config-1.14&quot; in namespace kube-system with the configuration for the kubelets in the cluster</div><div>[upload-certs] Storing the certificates in ConfigMap &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace</div><div>[upload-certs] Using certificate key:</div><div>140694b70a67b1e18e14deca38ff7a2bd3c3cd2c52d548692200b8388274a3d2</div><div>[mark-control-plane] Marking the node master01 as control-plane by adding the label &quot;node-role.kubernetes.io/master=''&quot;</div><div>[mark-control-plane] Marking the node master01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</div><div>[bootstrap-token] Using token: wu6jag.i2kp6xpmue82tzqf</div><div>[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</div><div>[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</div><div>[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</div><div>[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</div><div>[bootstrap-token] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</div><div>[addons] Applied essential addon: CoreDNS</div><div>[addons] Applied essential addon: kube-proxy</div><div><br/></div><div>Your Kubernetes control-plane has initialized successfully!</div><div><br/></div><div>To start using your cluster, you need to run the following as a regular user:</div><div><br/></div><div>  mkdir -p $HOME/.kube</div><div>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</div><div>  sudo chown $(id -u):$(id -g) $HOME/.kube/config</div><div><br/></div><div>You should now deploy a pod network to the cluster.</div><div>Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</div><div>  https://kubernetes.io/docs/concepts/cluster-administration/addons/</div><div><br/></div><div>You can now join any number of the control-plane node running the following command on each as root:</div><div><br/></div><div>  kubeadm join 192.168.70.5:6443 --token wu6jag.i2kp6xpmue82tzqf \</div><div>    --discovery-token-ca-cert-hash sha256:ba5fdee24f624cab1c8d91cb9c464aadb96efe34185bb6a0f2440af27692724e \</div><div>    --experimental-control-plane --certificate-key 140694b70a67b1e18e14deca38ff7a2bd3c3cd2c52d548692200b8388274a3d2</div><div><br/></div><div>Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</div><div>As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use</div><div>&quot;kubeadm init phase upload-certs --experimental-upload-certs&quot; to reload certs afterward.</div><div><br/></div><div>Then you can join any number of worker nodes by running the following on each as root:</div><div><br/></div><div>kubeadm join 192.168.70.5:6443 --token wu6jag.i2kp6xpmue82tzqf \</div><div>    --discovery-token-ca-cert-hash sha256:ba5fdee24f624cab1c8d91cb9c464aadb96efe34185bb6a0f2440af27692724e</div></div><div>其中：</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div># 用于配置kubectl认证到apiserver</div><div>  mkdir -p $HOME/.kube</div><div>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</div><div>  sudo chown $(id -u):$(id -g) $HOME/.kube/config</div><div><br/></div><div># 用于其他master节点加入集群</div><div>kubeadm join 192.168.70.5:6443 --token wu6jag.i2kp6xpmue82tzqf \</div><div>    --discovery-token-ca-cert-hash sha256:ba5fdee24f624cab1c8d91cb9c464aadb96efe34185bb6a0f2440af27692724e \</div><div>    --experimental-control-plane --certificate-key</div><div><br/></div><div># 用于node节点加入集群</div><div>kubeadm join 192.168.70.5:6443 --token wu6jag.i2kp6xpmue82tzqf \</div><div>    --discovery-token-ca-cert-hash sha256:ba5fdee24f624cab1c8d91cb9c464aadb96efe34185bb6a0f2440af27692724e</div></div><div>注意：</div><div># 上面用到的token跟证书值都是两小时有效的，过期以后依次执行下面步骤重新生成</div><div>## 加入命令格式：</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div># 控制平面重新加入集群的方法</div><div>kubeadm join --token &lt;token&gt; &lt;master-ip&gt;:&lt;master-port&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt; --experimental-control-plane --certificate-key &lt;cert值&gt;</div><div># work节点重新加入集群的方法</div><div>kubeadm join --token &lt;token&gt; &lt;master-ip&gt;:&lt;master-port&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt;</div></div><div>## 证书hash值生成：此hash是唯一不变的，丢失加入指令时可使用此命令生成</div><div>openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>ba5fdee24f624cab1c8d91cb9c464aadb96efe34185bb6a0f2440af27692724e</div></div><div>## token值生成：生成token并且组成加入命令</div><div>kubeadm token create --print-join-command</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div># 得到一条完整的node节点加入集群的命令，可以用此条命令添加新的node到集群</div><div>kubeadm join 192.168.70.5:6443 --token kbw101.u8n0zwpub0m8b0o4     --discovery-token-ca-cert-hash sha256:ba5fdee24f624cab1c8d91cb9c464aadb96efe34185bb6a0f2440af27692724e</div></div><div>## 生成证书值，结合上面生成的token来将master加入集群</div><div>kubeadm init phase upload-certs --experimental-upload-certs</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div># 得到一条hash值，结合上面生成的token来组成一条master加入集群的命令</div><div>I0618 15:41:55.339931    2962 version.go:96] could not fetch a Kubernetes version from the internet: unable to get URL &quot;https://dl.k8s.io/release/stable-1.txt&quot;: Get https://dl.k8s.io/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)</div><div>I0618 15:41:55.340190    2962 version.go:97] falling back to the local client version: v1.14.3</div><div>[upload-certs] Storing the certificates in ConfigMap &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace</div><div>[upload-certs] Using certificate key:</div><div>881a3b10559a21bf9c93fefb7466cc3b21b6eb8bbd63331e014cb32831b6654c</div><div>上面报错没关系，因为访问不了网站，重点是最后一行的的hash值</div><div><br/></div><div># 使用上面生成的token跟hash值生成命令，将hash值加到--experimental-control-plane --certificate-key后</div><div>kubeadm join 192.168.70.5:6443 --token kbw101.u8n0zwpub0m8b0o4     --discovery-token-ca-cert-hash sha256:ba5fdee24f624cab1c8d91cb9c464aadb96efe34185bb6a0f2440af27692724e --experimental-control-plane --</div><div>certificate-key 881a3b10559a21bf9c93fefb7466cc3b21b6eb8bbd63331e014cb32831b6654c</div></div><div><br/></div><div>### 配置kubectl</div><div>[root@master01 ~]# mkdir -p $HOME/.kube</div><div>[root@master01 ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</div><div>[root@master01 ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config</div><div><br/></div><hr/><div># 其他master节点部署</div><div>### 镜像导入（当无法使用梯子时使用）</div><div>链接：<a href="https://pan.baidu.com/s/1W_fF8gwUOAJUrKxA1q4eiA">https://pan.baidu.com/s/1W_fF8gwUOAJUrKxA1q4eiA</a></div><div>提取码：zvny</div><div>docker image load -i <span style="min-height: 1pt; font-family: 微软雅黑; color: rgb(51, 51, 51);">k8s-master.gz</span></div><div><br/></div><div>## 使用第一个master节点生成加入命令来加入集群</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>[root@master02 ~]# kubeadm join 192.168.70.5:6443 --token wu6jag.i2kp6xpmue82tzqf \</div><div>    --discovery-token-ca-cert-hash sha256:ba5fdee24f624cab1c8d91cb9c464aadb96efe34185bb6a0f2440af27692724e \</div><div>    --experimental-control-plane --certificate-key --ignore-preflight-errors=Swap</div></div><div><br/></div><div>## 配置kubectl</div><div>[root@master02 ~]# mkdir -p $HOME/.kube</div><div>[root@master02 ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</div><div>[root@master02 ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config</div><div><br/></div><hr/><div># 其他node节点部署</div><div>### 镜像导入（当无法使用梯子时使用）</div><div>链接：<a href="https://pan.baidu.com/s/1_kMcaJr5-GEJJknQEs4M7w">https://pan.baidu.com/s/1_kMcaJr5-GEJJknQEs4M7w</a></div><div>提取码：cgms</div><div>docker image load -i <span style="min-height: 1pt; font-family: 微软雅黑; color: rgb(51, 51, 51);">k8s-node.gz</span></div><div><span style="min-height: 1pt; font-family: 微软雅黑; color: rgb(51, 51, 51);"><br/></span></div><div><span style="color: rgb(51, 51, 51);">## 使用第一个master节点生成加入命令来加入集群</span></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.15);-en-codeblock:true;"><div>[root@node01 ~]# kubeadm join 192.168.70.5:6443 --token wu6jag.i2kp6xpmue82tzqf \</div><div>    --discovery-token-ca-cert-hash sha256:ba5fdee24f624cab1c8d91cb9c464aadb96efe34185bb6a0f2440af27692724e 、</div><div>--ignore-preflight-errors=Swap</div></div><div><br/></div><hr/><div># 部署网络插件，此处使用flannel</div><div>### flannel的镜像已包含在上面两个镜像包里面</div><div>### flannel清单文件（当无法下载时使用）</div><div>链接：<a href="https://pan.baidu.com/s/1P0ci0Sz2n-oh3Rt0mHCUSA">https://pan.baidu.com/s/1P0ci0Sz2n-oh3Rt0mHCUSA</a></div><div>提取码：ccxv</div><div><br/></div><div>[root@master01 ~]# kubectl apply -f <a href="https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml">https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</a></div><div><br/></div><hr/><div># 检查部署结果</div><div>[root@master01 ~]# kubectl get nodes -o wide</div><div>可以看见ready状态的master与node节点</div><div><img src="kubernetes 1.14.3高可用kubeadm部署_files/Image [5].png" type="image/png" data-filename="Image.png"/></div><div><br/></div><div>[root@master01 ~]# kubectl get pods -n kube-system -o wide</div><div><img src="kubernetes 1.14.3高可用kubeadm部署_files/Image [6].png" type="image/png" data-filename="Image.png"/></div><div><br/></div><div>[root@master01 ~]# kubectl get svc -n kube-system</div><div><img src="kubernetes 1.14.3高可用kubeadm部署_files/Image [7].png" type="image/png" data-filename="Image.png"/></div><div><br/></div><div># node节点上查看转发模式是否为ipvs</div><div>[root@node01 ~]# yum -y install ipvsadm</div><div><img src="kubernetes 1.14.3高可用kubeadm部署_files/Image [8].png" type="image/png" data-filename="Image.png"/></div><div><br/></div></div></span>
</div></body></html> 